# Java-сервисы — 2025-11-26T15:41:08+00:00

Итог: три Java-процесса (user `eywa`), суммарно ~732 MiB RSS (~9.3% RAM). CPU у всех <0.6% — явных утечек или разгона не видно в момент замера. Основное давление на память идёт от других сервисов (Node/Gemini), но Java даёт заметный базовый фон.

## Детали процессов
| Service | PID | CPU% | MEM% | RSS MiB | Основные флаги/назначение |
|---------|-----|------|------|---------|---------------------------|
| Keycloak (dev) | 3222072 | 0.3 | 5.7 | 459 | Quarkus `start-dev`, `-XX:MaxRAMPercentage=70`, G1GC |
| Kafka broker | 3472397 | 0.5 | 2.2 | 177 | `-Xmx1G -Xms1G`, G1GC, GC-логи `/var/log/kafka/kafkaServer-gc.log` |
| Zookeeper | 3463819 | 0.2 | 1.4 | 114 | `-Xmx512M -Xms512M`, G1GC, GC-логи `/var/log/kafka/zookeeper-gc.log` |

## Что обратить внимание
- Keycloak: `MaxRAMPercentage=70` на хосте с 7.6 GiB позволяет забрать до ~5 GiB, хотя фактический RSS ~459 MiB. Если нужно снизить базовую нагрузку, задайте фиксированное `-Xmx512m` (или меньше) вместо процентов.
- Kafka/Zookeeper: оба на G1GC, низкий CPU, RSS в пределах заданных Xmx/Xms. По GC-логам можно увидеть паузы/рост heap: `tail -n 50 /var/log/kafka/*gc.log`.
- Swap занят 4.8 GiB — но Java-процессы маленькие и маловероятно являются причиной свопинга. Основные потребители памяти — Node/Gemini, dotnet, dockerd.

## Быстрые проверки при подозрении на утечки
- Снимок heap/G1: `sudo jcmd <pid> GC.heap_info` и `sudo jstat -gc <pid> 1s 5` (если есть пароль sudo).
- Оценка объектов: `sudo jmap -histo:live <pid> | head` — покажет топ-объекты в живом heap.
- Мониторинг в динамике: `watch -n 5 "ps -p <pid> -o pid,pcpu,pmem,rss,args"` чтобы увидеть тренд RSS/CPU.

## Если хочется освободить память
- Уменьшить heap Keycloak (см. выше) или выключить dev-профиль, если не нужен.
- Остановить Kafka/Zookeeper на время, если тестовый стенд сейчас не используется.
- Глянуть логов на предмет долгих GC/OutOfMemory, но текущих симптомов нет.

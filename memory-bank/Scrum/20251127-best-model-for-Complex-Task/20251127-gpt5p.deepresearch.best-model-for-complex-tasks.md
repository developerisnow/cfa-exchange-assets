# Сравнение Codex 5.1 High‑Max, GPT‑5.1 High, Claude Opus 4.5 и Gemini 3 для DevOps‑задач

## Подходящесть моделей для DevOps‑задач

**Codex 5.1 High‑Max (OpenAI Codex Max)** – специализируется на программировании, поэтому отлично справляется с задачами типа *«инфраструктура как код»*, автоматизацией и CI/CD-пайплайнами. Эта модель может непосредственно работать с кодовыми репозиториями (например, читать код на GitHub и готовить pull request’ы)[\[1\]](https://www.reddit.com/r/ChatGPTPro/comments/1ko46h4/chatgpt_codex_initial_thoughts_on_how_its_affects/#:~:text=Codex%20CLI%20was%20not%20that,and%20get%20pull%20request%20ready). По отзывам разработчиков, Codex Max генерирует чистый, рабочий код для бэкенда и unit-тестов лучше, чем другие модели[\[2\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=CC%20and%20Codex). Однако отмечается, что Codex ориентирован именно на код: он не силён в дизайне интерфейсов и визуальных задачах (может даже не заметить явных проблем UI)[\[3\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Codex%20is%20much%2C%20much%20better,functional%20backend%20code%20and%20tests). Тем не менее, новейшая версия Codex Max позиционируется как важный инструмент для DevOps-команд – она упрощает интеграцию с окружением разработки и ускоряет процессы, помогая поддерживать высокий уровень в цикле разработки, тестирования и деплоя ПО[\[4\]](https://www.devopschat.co/articles/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper#:~:text=The%20Codex%20Max%20model%20not,in%20their%20software%20development%20processes).

**GPT‑5.1 High** – более общая модель от OpenAI, способная к программированию, но не заточенная узко под код. В контексте DevOps она проявляет себя как “мозговой центр”: хорошо понимает архитектуру, документацию и может стратегически планировать изменения. В одном реальном тесте GPT-5.1 High, проанализировав изменения в репозитории и документации, дала развёрнутый ретроспективный отчёт и дорожную карту улучшений – почти как опытный тимлид[\[5\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,more%20narrative%20answer%2C%20but%20it). То есть она не только перечисляет задачи, но и указывает на процессы, тестовую инфраструктуру, качество документации и т.д. Такой подход ценен в DevOps: модель способна обобщать информацию (например, из описания инфраструктуры или логов) и предлагать улучшения на высоком уровне, а не просто генерировать скрипт. Разработчик, сравнивший GPT‑5.1 High с Codex Max на реальном проекте, в итоге **предпочёл GPT‑5.1 High для большинства задач** – особенно там, где нужна правильность и продуманность, а не максимальная скорость[\[6\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=TLDR%3B%20After%20extensive%20real%20world,5.1%20High%22%20model%20for%20everything).

**Claude Opus 4.5 (Anthropic)** – новейшая модель от Anthropic, которая считается *“лучшей в мире для кодинга, агентов и работы с компьютером”*[\[7\]](https://www.reddit.com/r/Anthropic/comments/1p5pmyn/introducing_claude_opus_45_our_strongest_model_to/#:~:text=Claude%20Opus%204,in%20how%20work%20gets%20done). Она изначально ориентирована на код, но, по отзывам, отличается выдающейся универсальностью. Opus 4.5 уверенно ведёт долгие сессии, умеет выполнять сложные многошаговые сценарии и управлять инструментами. В контексте DevOps это проявляется в том, что модель способна автоматизировать операционные задачи: один пользователь рассказал, как Claude (версия Code) подняла десяток виртуальных машин, сама подключалась к ним по SSH, отслеживала логи и давала сводку – фактически взяв на себя часть *“ручной”* работы SRE-инженера[\[8\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=%E2%80%A2%20%203mo%20ago). Кроме того, сообщество отмечает, что Claude *“просто зверь”* в создании CI/CD-конвейеров со всеми шагами – от прогона линтеров и тестов до сборки и публикации Docker-образов[\[9\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=CC%20is%20absolutely%20beast%20on,and%20publish%20docker%20images%2C%20etc). При этом Anthropic уверяет, что Opus 4.5 улучшен не только в кодинге, но и в *обычных повседневных задачах* (работа с документами, таблицами и т.д.), что намекает на его пригодность для широкого спектра DevOps-активностей[\[7\]](https://www.reddit.com/r/Anthropic/comments/1p5pmyn/introducing_claude_opus_45_our_strongest_model_to/#:~:text=Claude%20Opus%204,in%20how%20work%20gets%20done).

**Gemini 3 (Google)** – перспективная модель от Google с огромным контекстом (более миллиона токенов) и мультимодальными возможностями. В теории это даёт преимущества для DevOps-задач: Gemini может поглотить *очень* большие конфигурации, логи или документацию целиком и, возможно, даже обрабатывать визуальные данные (например, схемы архитектуры) – то есть обладает **широким “кругозором”**. Некоторые разработчики описывают Gemini как модель с “знаниями старшего инженера” и обширной эрудицией по доменам[\[10\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=Long%20term%20and%20short%20term,and%20power%20but%20needs%20structure). Она хорошо подходит для **рутинного использования**, в том числе из\-за более низкой цены по сравнению с конкурентами[\[11\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=The%20issue%20on%20%E2%80%9Cprice%E2%80%9D%20is,they%20removed%20the%20opus%20limits). Однако, на практике в узкоспециализированных задачах Gemini пока уступает: её часто ставят на *3-е место* после OpenAI и Anthropic по качеству кодогенерации[\[12\]](https://www.reddit.com/r/Bard/comments/1p1n3f2/gpt51codexmax_extra_highxhigh_is_working_a_lot/#:~:text=Gemini%20is%20squarely%20number%203,is%20dead%20set%20on%20that). Пользователи указывают, что Gemini порой даёт больше ложных выводов и *«галлюцинаций»*, особенно в сложных технических вопросах[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much)[\[14\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago). То есть для DevOps-скриптов и инфраструктурного кода Gemini 3 может работать, но требует более тщательной проверки результатов.

## Codex 5.1 High‑Max – узкая заточка под код

Сообщество активно обсуждает, насколько специализированность Codex 5.1 High‑Max ограничивает его вне сферы программирования. **Общее мнение:** эта модель действительно *“заточена”* под код, и это проявляется двояко. С одной стороны, Codex-Max изначально обучена на агентных задачах в области софтверной инженерии[\[15\]](https://thenewstack.io/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper/#:~:text=OpenAI%20Says%20Its%20New%20Codex,It%27s%20meant%20to%20handle) – написание функций, ответ на вопросы по коду, отладка багов и даже автогенерация pull request’ов[\[16\]](https://openai.com/index/introducing-codex/#:~:text=Introducing%20Codex%20,proposing%20pull%20requests%20for%20review). За счёт этого она превосходно справляется с конкретными задачами разработки. Например, Codex выдаёт минимальный необходимый код, чтобы решить поставленную проблему, без лишнего “раздувания” решения[\[17\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=%E2%80%A2%20%203mo%20ago). Это экономит время и упрощает чтение кода. В реальных сценариях многие отмечают, что Codex пишет **чище и короче** там, где другой ИИ может выдать более многословное решение[\[18\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Codex%20writes%20smaller%2C%20shorter%2C%20cleaner,code%20is%20still%20a%20beast).

С другой стороны, **узкая специализация означает ограничения в широте мышления**. Codex 5.1-Max склонен трактовать задачу сугубо в терминах программирования. Если вопрос выходит за рамки написания кода (например, касается архитектурных решений, организационных рекомендаций или творчества), Codex может либо попытаться перевести его в плоскость кода, либо дать менее развитый ответ. Так, в сравнительном тесте на проекте Codex Max выдал краткий чек-лист предстоящих задач, но упустил один нюанс архитектуры, который был явно описан в документации (он предложил изменить компонент, который **уже** был исправлен ранее)[\[19\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,route%E2%80%9D%20as%20a%20next%20task)[\[20\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,of%20date%20on%20that%20detail). GPT‑5.1 High, читая те же самые данные, избежал этой ошибки и понял контекст правильно. Причина в том, что Codex фокусировался на конкретных изменениях в коде, а не на общих решениях – он “поторопился” составить список дел, не перепроверив дизайн-документ[\[21\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,made%20a%20few%20commits%20ago).

Кроме того, узкая ориентация Codex проявилась в визуальных задачах: один из разработчиков попытался доверить ему оценку UI, и Codex “похвалил” скриншот с ужасно размазанным интерфейсом, не заметив проблемы стилей[\[3\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Codex%20is%20much%2C%20much%20better,functional%20backend%20code%20and%20tests). Это пример того, что вне мира чистого кода (где требуются дизайнерские или контекстные знания) модель может дать неадекватный ответ. Также отмечается, что Codex требует чёткой постановки задачи. Если запрос слегка расплывчат или выходит за шаблон, Codex либо запросит уточнений, либо сделает предположение, которое может оказаться неверным[\[22\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=This%20isn%27t%20meant%20to%20sound,you%20are%20better%20at%20backend). В то время как более универсальные модели способны сами догадаться, *“что имел в виду”* неопытный пользователь, Codex предпочитает получить явные инструкции.

Итого, **специализация Codex 5.1 High‑Max на коде – это палка о двух концах**. Она даёт непревзойдённую эффективность в чисто программных задачах (генерация кода, отладка, тестирование), но может ограничивать модель, когда задача выходит за эти рамки. В контексте DevOps это значит, что Codex великолепно напишет скрипт деплоя или Terraform-манифест, но обсуждать с ним архитектуру системы или стратегию масштабирования может быть менее продуктивно – он, вероятно, сконцентрируется на конкретных конфигурациях и упустит более широкие соображения. Тем не менее, OpenAI явно пытается сделать Codex полезным и на уровне процессов: по некоторым обзорам, Codex Max уже упрощает workflow разработчиков и DevOps-инженеров, беря на себя рутинные задачи и повышая их продуктивность[\[4\]](https://www.devopschat.co/articles/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper#:~:text=The%20Codex%20Max%20model%20not,in%20their%20software%20development%20processes). Просто нужно помнить о границах его “кругозора” и при необходимости дополнять его более общими моделями.

## Интеллектуальная гибкость и высокоуровневые ответы

**GPT‑5.1 High** демонстрирует наибольшую гибкость мышления среди рассматриваемых моделей. Пользователи описывают работу с ней как взаимодействие с очень опытным инженером или архитектором. Например, упомянутый ранее сравнительный эксперимент показал, что GPT‑5.1 High не просто перечисляет изменения, но и размышляет о процессах: предлагает улучшить документацию, синхронизировать тесты с кодом, планирует фазовый рефакторинг – словом, даёт **высокоуровневые рекомендации**, выходящие за рамки конкретного кода[\[5\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,more%20narrative%20answer%2C%20but%20it). Ответ GPT‑5.1 High был длиннее и повествовательнее, *зато содержал нюансы и обоснования*, как если бы опытный тимлид проводил ревью последнего спринта[\[5\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,more%20narrative%20answer%2C%20but%20it). Благодаря этому GPT‑5.1 High отлично справляется с абстрактными вопросами: будь то стратегия резервного копирования, план мониторинга или анализ пробелов в DevOps-процессах – модель способна рассуждать и предлагать осмысленные идеи, а не только выдать кусок кода.

**Codex 5.1 High‑Max** по интеллектуальной гибкости более прямолинеен. Он стремится сразу перевести запрос в плоскость действий. Если спросить что-то широкое («как нам улучшить надежность инфраструктуры?»), Codex, вероятно, ответит списком конкретных технических шагов (например, *“настроить Health-checkи, внедрить ретраи, добавить мониторинг”*), но может проигнорировать некоторые неочевидные аспекты. В уже приводившемся сравнении Codex дал **чёткий, сжатый список задач** и даже проставил приоритеты и уровень риска для каждого пункта[\[23\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=What%20GPT%E2%80%915)[\[24\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=more%20discoverable%20for%20devs) – в этом проявляется его ориентация на выполнение. Однако он почти не пояснял *почему* эти шаги нужны и мало говорил о долгосрочной перспективе. Когда требовалось учесть дизайн-решения (например, умышленно оставленные старые маршруты в коде), Codex Extra High предложил их переделать, хотя в проекте было задокументировано решение их пока не трогать[\[25\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,prioritized%20tasks%20with%20risk%20hints). То есть модель не всегда следует негласным замыслам архитектора – она скорее универсальный **“исполнитель”**, чем **“советник”**. Тем не менее, в рамках своей области Codex весьма умен: он эффективно разбивает задачу на подзадачи, может сам придумать тесты или сценарии развертывания. Просто его интеллект проявляется *внутри* программирования, а не в философских рассуждениях.

**Claude Opus 4.5** сочетает сильные стороны первых двух. Будучи, как и Codex, натренирован на код и инструменты, Claude при этом сохраняет широту мышления от своей оригинальной (более общей) версии. Разработчики делятся примерами, как Claude решает творческие и высокоуровневые задачи, недоступные чисто “кодовой” модели. Например, один пользователь предоставил Claude брендовое руководство (PDF) и попросил стилизовать интерфейс в соответствии с ним – **Claude смог извлечь нужную информацию и применить её в дизайне**, тогда как Codex провалился, не сумев использовать PDF-данные[\[26\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Claude%27s%20output%20was%20a%20strong,Codex%20failed%20miserably%20at%20that). Это говорит о том, что Claude может выходить за рамки кода и понимать контекст, написанный человеческим языком. Также в обсуждениях отмечается, что Claude лучше придерживается инструкции, не уходит в ненужные детали и генерирует меньше выдуманной информации, чем конкуренты[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much). Его **креативность** тоже на высоте: многие авторы, использующие ИИ для генерации текстов или нетехнических задач, предпочитают Claude – и хотя в Opus 4.5 упор на код, базовая способность к творческим и абстрактным ответам у него сохранилась. По сути, Opus 4.5 многие называют моделью, “которой можно решать все задачи”[\[27\]](https://www.reddit.com/r/ClaudeAI/comments/1p5s2mz/unbelievable_i_can_use_opus_45_for_all_tasks/#:~:text=Unbelievable%20I%20can%20use%20Opus,Thanks%20Anthropic), без тщательного планирования переключения между разными ИИ. Впрочем, есть мнение, что Claude иногда требует более структурированного подхода: ему полезно задавать чёткий план или подключать его к инструментам, тогда он проявит максимум потенциала[\[10\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=Long%20term%20and%20short%20term,and%20power%20but%20needs%20structure). Но в правильных руках это **универсальный помощник**, способный и код написать, и проблему в системе диагностировать, и вариантов решений набросать.

**Gemini 3** как универсальная модель от Google также обладает значительной интеллектуальной гибкостью, по крайней мере на бумаге. Её мультимодальность и огромный контекст теоретически позволяют погружаться в разные виды данных и давать развернутые ответы. Некоторые отмечают, что **общеэрудированности** у Gemini много – она может подтянуть знания из разных доменов, что полезно, если DevOps-задача сопряжена, например, с бизнес-контекстом или редким инструментом[\[10\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=Long%20term%20and%20short%20term,and%20power%20but%20needs%20structure). В планировании и структурировании решений Gemini тоже должна быть сильна (недаром речь идёт о “знаниях senior-инженера”). Однако на практике пользователи столкнулись с тем, что ответы Gemini порой менее надежны. Она может придумать несуществующие детали или уверенно утверждать что-то неверное (то есть **галлюцинировать**) в ситуациях, где GPT- или Claude-модели более осторожны[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much)[\[14\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago). Это ограничивает её реальную полезность в высокоуровневых обсуждениях: если модель неожиданно выдаёт ложный тезис (например, об особенностях Kubernetes, которых нет, или о несуществующем ограничении CI-системы), доверять её стратегическим выводам сложно без перепроверки. Таким образом, интеллектуальный потенциал у Gemini 3 огромный, но *фактическая точность* пока немного подводит. Её можно эффективно использовать для брейншторминга идей или обзора технологий (получив сразу «энциклопедическую» справку по теме), однако при принятии решений большинство инженеров пока предпочитают перепроверить выводы Gemini по надежным источникам или с помощью другой модели.

## Производительность, надёжность и работа с неопределёнными запросами

**GPT‑5.1 High** ставит во главу угла корректность и глубину проработки ответа, пусть даже ценой скорости или краткости. В пользовательских испытаниях эта модель показала себя **очень надёжной**: она аккуратно читает предоставленные данные (код, diff’ы, документацию) и почти не допускает фактических ошибок в выводах. В описанном ранее сравнении GPT‑5.1 High единственная из трёх моделей верно поняла, что одно из предложений Codex (переключить старый роутинг на новый) уже не актуально – код был давно исправлен[\[19\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,route%E2%80%9D%20as%20a%20next%20task)[\[20\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,of%20date%20on%20that%20detail). Тем самым GPT‑5.1 High избежала лишней работы и потенциальной ошибки, тогда как Codex выдала устаревший пункт в план. Разработчик отмечает, что GPT‑5.1 High хоть и отвечает более развёрнуто, **экономит его усилия на проверку** – ей можно доверять обзор проекта целиком, вместо того чтобы перепроверять каждый шаг модели поменьше[\[28\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,just%20shuffling%20it). По скорости GPT‑5.1 High, конечно, не столь стремительна, как узкоспециализированные варианты, но она всё ещё достаточно быстра для практической работы. Кроме того, её умение понимать даже расплывчатые вопросы делает работу комфортнее: если запрос сформулирован не идеально, GPT‑5.1 High сама уточнит или догадается, что нужно, вместо того чтобы сразу генерировать неверный код. Для плохо проработанных (нечётких) запросов это **лучший выбор** – она направит уточняющие вопросы или даст общее решение, которое можно уточнять дальше.

**Codex 5.1 High‑Max** стремится решать задачу максимально эффективно, но предполагает, что пользователь точно знает, чего хочет. Если описание задачи чёткое и детальное, Codex сработает как **точный инструмент**: быстро напишет код, который в большинстве случаев запускается с первого раза или требует минимальных исправлений. Многие разработчики хвалят Codex за следование заданию *«в точности и ничего лишнего»* – он, как выразились на Reddit, *“пишет минимальный код, чтобы задача заработала”*[\[17\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=%E2%80%A2%20%203mo%20ago). **Производительность** Codex в плане качества кода очень высока: он генерирует лаконичные, чистые решения без склонности “переусложнять” задачу. Например, один пользователь сравнивал подход Anthropic Claude и Codex: Claude иногда пытается сделать “супер-приложение” из простой задачи (overengineering), в то время как Codex просто пишет то, что просят[\[22\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=This%20isn%27t%20meant%20to%20sound,you%20are%20better%20at%20backend). Однако у этой прагматичности есть и обратная сторона – **ошибки при неопределённом вводе**. Codex не любит неясности: если задача сформулирована туманно, модель может сделать неверные допущения. В отличие от более «гибких» ИИ, Codex не будет долго уточнять контекст – он либо запросит уточнение, либо рискнёт взять очевидное решение, которое может не совпадать с истинными ожиданиями. Уже упомянутый пример с лишним пунктом в списке задач иллюстрирует эту проблему: модель уверенно внесла уже реализованную фичу в TODO-лист[\[20\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,of%20date%20on%20that%20detail). Поэтому опытные пользователи советуют: **для максимальной надёжности с Codex формулируйте чёткие требования** и проверяйте критичные результаты. Впрочем, отмечается, что Codex в принципе меньше склонен фантазировать за пределами кода – он редко будет «выдумывать» факты из реального мира, его область – это код и dev-окружение. Там он весьма устойчив: в сравнении с Google Gemini Codex оказался гораздо надёжнее и меньше делал безосновательных предположений[\[29\]](https://www.reddit.com/r/Bard/comments/1p1n3f2/gpt51codexmax_extra_highxhigh_is_working_a_lot/#:~:text=%E2%80%A2%20%202h%20ago). Значит, если держать запросы в рамках технической конкретики, Codex 5.1-Max – очень устойчивый и предсказуемый помощник.

**Claude Opus 4.5** получил множество восторженных отзывов за сочетание скорости, точности и функциональности. По сравнению с предыдущими моделями Anthropic, Opus 4.5 значительно ускорился – разработчики замечают, что он выполняет многие действия почти мгновенно (например, запуск сервисов, анализ вывода)[\[30\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=One%20thing%20I%20haven%27t%20seen,designed%20atm). В одном комментарии сравнили, как Claude Code vs Codex запускают локальный сервер: Claude за \~3 секунды выполнил команду и начал стримить логи, а Codex задумался \~20 секунд, пытаясь воспроизвести запуск “теоретически” через какую-то процедуру с PID-файлами[\[31\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=I%20can%20start%20Claude%2C%20tell,output%20live%20to%20debug%20problems). То есть **в режиме агента (реального выполнения команд)** Claude оказался куда шустрее и практичнее, тогда как Codex, видимо, слишком буквально следует скриптам. Это показывает, что Opus 4.5 лучше справляется с непредусмотренными ситуациями и **реальным временем**, что важно для DevOps (где нужно реагировать на вывод команд, логи, результаты тестов на лету). В плане надёжности Claude Opus 4.5 тоже на высоте. Пользователи напрямую заявляют: *“в кодинге Opus снова король”*, особенно после снятия ограничений – сейчас даже в стандартном тарифе Anthropic большинство запросов идут сразу на Opus без снижения версии[\[11\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=The%20issue%20on%20%E2%80%9Cprice%E2%80%9D%20is,they%20removed%20the%20opus%20limits). В кодовых задачах Opus практически не ошибается: он показывает лучшую проходимость тестов и меньше галлюцинирует по сравнению с конкурентами[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much). Если Codex где\-то был эталоном точности, то появление Opus 4.5 подняло планку ещё выше – некоторые, кто раньше предпочитал Codex за минимальную необходимость правок, теперь признают превосходство Opus 4.5 или по крайней мере равенство между ними[\[32\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%205h%20ago). В случае плохо определённых запросов Claude обычно проявляет терпение: он может задать уточняющие вопросы или предложить несколько вариантов решения проблемы. В ранних версиях Claude иногда “перестарался” (старался построить слишком сложное решение, если вопрос оставлял простор), но опытные пользователи научились управлять этим через системные подсказки и настройку контекста[\[22\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=This%20isn%27t%20meant%20to%20sound,you%20are%20better%20at%20backend). Сейчас же Opus 4.5, судя по отзывам, **редко требует много итераций** – он и понимает с полуслова, и выполняет точно, особенно если его снабдить необходимым контекстом.

**Gemini 3** несколько уступает остальным по части надёжности, хотя по производительности (скорости генерации, объёму обрабатываемых данных) у него большие перспективы. В ранних отзывах Gemini фигурирует как модель, которая часто ошибается в деталях: *“галлюцинаций много”*[\[14\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago), *“фичи не доводит до конца”*, и т.п. Например, один из участников сравнения был удивлён, что даже более слабый Claude 4.5 Sonnet сумел дать правильные и творческие решения там, где Gemini 3 Pro ошибался[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much). Похоже, что на текущем этапе Google слегка недоработал точность модели – возможно, сказалась интеграция мультимодальности или недостаток обучения на сложных кодовых тестах. Помимо этого, на результаты Gemini влияет жёсткая политика безопасности Google. В сообществе отмечают: **“главная проблема – это фильтры”**[\[33\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=The%20problem%20is%20the%20safety), то есть модель иногда отказывается выполнять запросы или урезает ответ, если посчитает, что нарушает правила. В DevOps-контексте это может проявиться, например, когда просишь проанализировать логи на наличие уязвимостей – Gemini может счесть это потенциально опасным. Поэтому надёжность Gemini страдает и из\-за того, что ответ может быть не полным или излишне общим по не связанным с техникой причинам (она просто *не скажет лишнего*, “боясь” политики). Что касается нечетких запросов, Gemini, будучи обучена на огромном корпусе данных, конечно, попытается помочь. Но ввиду вышесказанных **особенностей** это может выглядеть так: модель уверенно выдаст решение, но в нём окажутся неточности, или она начнёт излишне перестраховываться. Впрочем, стоит упомянуть, что Google стремится улучшить Gemini – его предыдущие версии (Gemini 2.5) уже активно использовались и получали неплохие отзывы, и возможно со временем Gemini 3 догонит или превзойдёт конкурентов. Пока же картина такая: **для критичных задач требующих безошибочного результата в DevOps (например, миграция PROD-сервера без даунтайма)** профессионалы склоняются к OpenAI Codex/GPT или Anthropic Claude, тогда как Gemini рассматривают либо из соображений экономии, либо для экспериментов в некритичной среде[\[11\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=The%20issue%20on%20%E2%80%9Cprice%E2%80%9D%20is,they%20removed%20the%20opus%20limits).

## Выбор модели для сложных DevOps-задач

Подводя итог обсуждениям на Reddit, можно сказать, что **идеального единоличного лидера нет** – всё зависит от конкретных потребностей:

* Если вам нужна **стратегическая проработка, архитектурные советы и уверенность в корректности** – многие выбирают GPT‑5.1 High в роли главного советчика. Она действует как мудрый архитектор: анализирует кодовую базу, документацию, указывает узкие места и предлагает последовательный план действий[\[5\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,more%20narrative%20answer%2C%20but%20it). В сложных DevOps-сценариях (CI/CD для микросервисов, планирование отказоустойчивости, оптимизация процесса разработки) GPT‑5.1 High даст разносторонний ответ с пояснениями *почему так*, а не просто *что сделать*. Ее недостаток – иногда избыточная подробность и меньшая скорость – с лихвой окупается экономией времени на исправление ошибок и доработку пропущенных деталей[\[6\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=TLDR%3B%20After%20extensive%20real%20world,5.1%20High%22%20model%20for%20everything)[\[28\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,just%20shuffling%20it).

* Если приоритет – **быстро получить рабочий код/скрипт** и вы сами хорошо понимаете задачу, то **Codex 5.1 High‑Max** станет отличным выбором. Эта модель особенно популярна среди **опытных DevOps-инженеров и разработчиков**, которые чётко формулируют запрос: тогда Codex мгновенно выдаст готовое решение или минимум подсказок для решения. Например, для написания сложного Terraform или Ansible плейбука по заранее продуманному плану Codex сгенерирует конфигурации быстрее и, как правило, правильнее всех. Разработчики пишут, что Codex сейчас “безумно хорош на бэкенде”[\[34\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%205h%20ago) и часто им **восторгаются** за экономию итераций на отладку. Однако помните, что Codex – инструмент хирургический: ему нужно “скальпелем” обозначить проблему. В противном случае есть шанс получить либо уточняющий вопрос, либо решение *не совсем о том*. Для повышения надёжности Codex можно комбинировать с другой моделью – так делают некоторые: черновое решение и идеи берут у Claude или GPT, а уже финальный код генерируют через Codex, чтобы получить оптимально чистую реализацию[\[22\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=This%20isn%27t%20meant%20to%20sound,you%20are%20better%20at%20backend)[\[35\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=I%20bought%20the%20%2420%20plan,similar%20state%20as%20Claude%27s%20version).

* **Claude Opus 4.5** по совокупности факторов часто называют **лучшим универсальным выбором для DevOps на текущий момент**. Он близок к GPT‑5.1 High в умении рассуждать и понимать контекст, и одновременно конкурирует с Codex в качестве генерируемого кода. Фактически Opus 4.5 стремится закрыть потребности сразу и стратегического планирования, и кодирования. Из обсуждений видно, что после выхода Opus 4.5 многие пересмотрели свои рабочие процессы: кто-то пишет *“Codex всё ещё хорош, но Opus теперь впереди”*, кто-то говорит *“я вообще могу все задачи решать в Claude, не переключаясь”*[\[27\]](https://www.reddit.com/r/ClaudeAI/comments/1p5s2mz/unbelievable_i_can_use_opus_45_for_all_tasks/#:~:text=Unbelievable%20I%20can%20use%20Opus,Thanks%20Anthropic). Особенно ценят Claude Opus за то, что он **меньше ошибается и фантазирует**, чем конкуренты[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much), и за его способность реально исполнять шаги (подключаться к сервисам, читать логи) без долгих раздумий[\[31\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=I%20can%20start%20Claude%2C%20tell,output%20live%20to%20debug%20problems). Для DevOps, где часто надо *“посмотреть и тут же починить”*, это огромный плюс. Если вы готовы освоить его интеграции и платить несколько больше (Opus всё же дороже обычных моделей), он может стать незаменимым “дежурным инженером” 24/7.

* **Gemini 3** пока выглядит как компромиссный вариант. Он перспективен – Google вкладывается в него, и модель наверняка улучшится – но в отзывах продвинутых пользователей звучит прохладный тон. Gemini хвалят за **широту знаний** и потенциально лучшие мультимодальные фишки (для DevOps это может означать понимание диаграмм, скриншотов мониторинга и пр.), а также за низкий порог входа (цена, интеграция с Google-экосистемой). Но если речь о действительно **сложных DevOps-задачах с требованием надёжности**, пока **Gemini 3 Pro** проигрывает: его ставят *«номер три»* после OpenAI и Anthropic по качеству решений[\[12\]](https://www.reddit.com/r/Bard/comments/1p1n3f2/gpt51codexmax_extra_highxhigh_is_working_a_lot/#:~:text=Gemini%20is%20squarely%20number%203,is%20dead%20set%20on%20that). Высокий уровень галлюцинаций и излишняя “осторожность” из\-за фильтров – главные минусы на сегодня[\[36\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago). Тем не менее, у Gemini есть своя ниша: например, очень длинные контексты (описания инфраструктуры на сотни тысяч строк) ему по плечу, тогда как другие могут не уместить всё в окно ввода. Также, если задача связана с продуктами Google Cloud, возможно, Gemini обучен лучше в этих доменах.

**Вывод:** Для комплексных DevOps-задач, требующих не только кодирования, но и **стратегического мышления**, наиболее рекомендуемыми в кругах опытных инженеров сейчас являются GPT‑5.1 High и Claude Opus 4.5. GPT‑5.1 High – за её инженерную осторожность и широкий кругозор, Opus 4.5 – за комбинацию умного рассуждения с высочайшим качеством кода и интеграцией инструментов. Codex 5.1 High‑Max – великолепный выбор, если основная цель – быстро написать или исправить код (pipeline, скрипт, конфиг) и вы сами чётко контролируете постановку задачи; его можно считать своеобразным «исполнительным модулем», который следует использовать под надзором архитектора (будь то человек или другая модель)[\[37\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=3,for%20code%E2%80%9D%20isn%E2%80%99t%20free). Gemini 3 же на конец 2025 года больше рассматривается как **вспомогательный инструмент** – он может дать второе мнение или справку, но полагаться исключительно на него в критических местах рискованнее[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much)[\[14\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago).

В конечном счёте, многие эксперты советуют подходить прагматично: использовать сильные стороны каждой модели. Например, **сформулировать высокоуровневый план с помощью GPT‑5.1 High или Claude Opus**, а затем поручить части реализации Codex Max – для генерации безупречного кода инфраструктуры[\[22\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=This%20isn%27t%20meant%20to%20sound,you%20are%20better%20at%20backend)[\[35\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=I%20bought%20the%20%2420%20plan,similar%20state%20as%20Claude%27s%20version). Но если нужно выбрать что-то одно для сложного DevOps-вызова прямо сейчас, то исходя из обсуждений на Reddit, **Claude Opus 4.5** выглядит наиболее универсальным и надёжным “напарником”, а **GPT‑5.1 High** – лучшим “консультантом” в принятии архитектурных решений. Эти модели покажут наивысшую эффективность в паре с опытным инженером, помогая решить как узкотехнические, так и организационные задачи в сфере DevOps.

**Sources:** Пользовательские обзоры и сравнения моделей на Reddit (subreddits r/codex, r/ClaudeCode, r/Bard, r/Anthropic, r/ChatGPTPro) — включая отчёт о реальном проекте[\[6\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=TLDR%3B%20After%20extensive%20real%20world,5.1%20High%22%20model%20for%20everything)[\[5\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,more%20narrative%20answer%2C%20but%20it), обсуждения Opus 4.5 vs Gemini 3[\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much)[\[14\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago), отзывы о Codex vs Claude Code[\[3\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Codex%20is%20much%2C%20much%20better,functional%20backend%20code%20and%20tests)[\[22\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=This%20isn%27t%20meant%20to%20sound,you%20are%20better%20at%20backend) и др.; официальная информация OpenAI и Anthropic[\[7\]](https://www.reddit.com/r/Anthropic/comments/1p5pmyn/introducing_claude_opus_45_our_strongest_model_to/#:~:text=Claude%20Opus%204,in%20how%20work%20gets%20done)[\[4\]](https://www.devopschat.co/articles/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper#:~:text=The%20Codex%20Max%20model%20not,in%20their%20software%20development%20processes).

---

[\[1\]](https://www.reddit.com/r/ChatGPTPro/comments/1ko46h4/chatgpt_codex_initial_thoughts_on_how_its_affects/#:~:text=Codex%20CLI%20was%20not%20that,and%20get%20pull%20request%20ready) ChatGPT Codex \- Initial Thoughts on how its affects DevOps? : r/ChatGPTPro

[https://www.reddit.com/r/ChatGPTPro/comments/1ko46h4/chatgpt\_codex\_initial\_thoughts\_on\_how\_its\_affects/](https://www.reddit.com/r/ChatGPTPro/comments/1ko46h4/chatgpt_codex_initial_thoughts_on_how_its_affects/)

[\[2\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=CC%20and%20Codex) [\[3\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Codex%20is%20much%2C%20much%20better,functional%20backend%20code%20and%20tests) [\[8\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=%E2%80%A2%20%203mo%20ago) [\[9\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=CC%20is%20absolutely%20beast%20on,and%20publish%20docker%20images%2C%20etc) [\[17\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=%E2%80%A2%20%203mo%20ago) [\[18\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Codex%20writes%20smaller%2C%20shorter%2C%20cleaner,code%20is%20still%20a%20beast) [\[22\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=This%20isn%27t%20meant%20to%20sound,you%20are%20better%20at%20backend) [\[26\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=Claude%27s%20output%20was%20a%20strong,Codex%20failed%20miserably%20at%20that) [\[30\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=One%20thing%20I%20haven%27t%20seen,designed%20atm) [\[31\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=I%20can%20start%20Claude%2C%20tell,output%20live%20to%20debug%20problems) [\[35\]](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/#:~:text=I%20bought%20the%20%2420%20plan,similar%20state%20as%20Claude%27s%20version) I have used CC and Codex for 24 hours straight on my FOSS project, here are my findings : r/ClaudeCode

[https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i\_have\_used\_cc\_and\_codex\_for\_24\_hours\_straight\_on/](https://www.reddit.com/r/ClaudeCode/comments/1nan23i/i_have_used_cc_and_codex_for_24_hours_straight_on/)

[\[4\]](https://www.devopschat.co/articles/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper#:~:text=The%20Codex%20Max%20model%20not,in%20their%20software%20development%20processes) DevOpsChat | OpenAI Says Its New Codex-Max Model Is Better, Faster and Cheaper

[https://www.devopschat.co/articles/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper](https://www.devopschat.co/articles/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper)

[\[5\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,more%20narrative%20answer%2C%20but%20it) [\[6\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=TLDR%3B%20After%20extensive%20real%20world,5.1%20High%22%20model%20for%20everything) [\[19\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,route%E2%80%9D%20as%20a%20next%20task) [\[20\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,of%20date%20on%20that%20detail) [\[21\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,made%20a%20few%20commits%20ago) [\[23\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=What%20GPT%E2%80%915) [\[24\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=more%20discoverable%20for%20devs) [\[25\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,prioritized%20tasks%20with%20risk%20hints) [\[28\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=,just%20shuffling%20it) [\[37\]](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/#:~:text=3,for%20code%E2%80%9D%20isn%E2%80%99t%20free) Real World Comparison \- GPT-5.1 High vs GPT-5.1-Codex-Max High/Extra High : r/codex

[https://www.reddit.com/r/codex/comments/1p36j5h/real\_world\_comparison\_gpt51\_high\_vs\_gpt51codexmax/](https://www.reddit.com/r/codex/comments/1p36j5h/real_world_comparison_gpt51_high_vs_gpt51codexmax/)

[\[7\]](https://www.reddit.com/r/Anthropic/comments/1p5pmyn/introducing_claude_opus_45_our_strongest_model_to/#:~:text=Claude%20Opus%204,in%20how%20work%20gets%20done) Introducing Claude Opus 4.5: our strongest model to date : r/Anthropic

[https://www.reddit.com/r/Anthropic/comments/1p5pmyn/introducing\_claude\_opus\_45\_our\_strongest\_model\_to/](https://www.reddit.com/r/Anthropic/comments/1p5pmyn/introducing_claude_opus_45_our_strongest_model_to/)

[\[10\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=Long%20term%20and%20short%20term,and%20power%20but%20needs%20structure) [\[11\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=The%20issue%20on%20%E2%80%9Cprice%E2%80%9D%20is,they%20removed%20the%20opus%20limits) [\[13\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=I%20was%20testing%20Gemini%203,and%20doesn%27t%20hallucinate%20as%20much) [\[14\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago) [\[32\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%205h%20ago) [\[33\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=The%20problem%20is%20the%20safety) [\[34\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%205h%20ago) [\[36\]](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/#:~:text=%E2%80%A2%20%203h%20ago) It seems opus 4.5 is just too amazing even compared to gemini 3 : r/Bard

[https://www.reddit.com/r/Bard/comments/1p5q4eq/it\_seems\_opus\_45\_is\_just\_too\_amazing\_even/](https://www.reddit.com/r/Bard/comments/1p5q4eq/it_seems_opus_45_is_just_too_amazing_even/)

[\[12\]](https://www.reddit.com/r/Bard/comments/1p1n3f2/gpt51codexmax_extra_highxhigh_is_working_a_lot/#:~:text=Gemini%20is%20squarely%20number%203,is%20dead%20set%20on%20that) [\[29\]](https://www.reddit.com/r/Bard/comments/1p1n3f2/gpt51codexmax_extra_highxhigh_is_working_a_lot/#:~:text=%E2%80%A2%20%202h%20ago) gpt-5.1-codex-max extra high(xhigh) is working a lot better for real world SWE tasks than gemini 3 pro. gemini is a good "coder" but codex is way better. : r/Bard

[https://www.reddit.com/r/Bard/comments/1p1n3f2/gpt51codexmax\_extra\_highxhigh\_is\_working\_a\_lot/](https://www.reddit.com/r/Bard/comments/1p1n3f2/gpt51codexmax_extra_highxhigh_is_working_a_lot/)

[\[15\]](https://thenewstack.io/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper/#:~:text=OpenAI%20Says%20Its%20New%20Codex,It%27s%20meant%20to%20handle) OpenAI Says Its New Codex-Max Model Is Better, Faster and Cheaper

[https://thenewstack.io/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper/](https://thenewstack.io/openai-says-its-new-codex-max-model-is-better-faster-and-cheaper/)

[\[16\]](https://openai.com/index/introducing-codex/#:~:text=Introducing%20Codex%20,proposing%20pull%20requests%20for%20review) Introducing Codex \- OpenAI

[https://openai.com/index/introducing-codex/](https://openai.com/index/introducing-codex/)

[\[27\]](https://www.reddit.com/r/ClaudeAI/comments/1p5s2mz/unbelievable_i_can_use_opus_45_for_all_tasks/#:~:text=Unbelievable%20I%20can%20use%20Opus,Thanks%20Anthropic) Unbelievable I can use Opus 4.5 for all tasks : r/ClaudeAI \- Reddit

[https://www.reddit.com/r/ClaudeAI/comments/1p5s2mz/unbelievable\_i\_can\_use\_opus\_45\_for\_all\_tasks/](https://www.reddit.com/r/ClaudeAI/comments/1p5s2mz/unbelievable_i_can_use_opus_45_for_all_tasks/)